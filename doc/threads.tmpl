            +-------------------+
            |       OS 211      |
            |  TASK 1: THREADS  |
            |  DESIGN DOCUMENT  |
            +-------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Owen Davies        <tod11@doc.ic.ac.uk>
Daniel Hertz       <dh611@doc.ic.ac.uk>
Charlie Hothersall <cjh111@doc.ic.ac.uk>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

                 ALARM CLOCK
                 ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

struct thread
  {
    :
    :
    snip
    :
    :

    /* Used by timer.c to check if thread should be blocked or unblocked */
    uint64_t time_to_sleep;

    :
    :
    snip
    :
    :
  };

The time_to_sleep member has been added to allow each thread to keep track of
the time that it is required to sleep. Other new members are not relevant to
this section.

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

In timer_sleep(), we check that the tick value supplied is positive (do nothing
if it's non-positive), update the time_to_sleep member in the current thread,
disable interrupts and block the current thread.

In the timer interrupt, we increment the ticks static variable, then check if
any thread needs unblocking by calling the check_thread() function. If we are
using the advanced scheduler, then we update the recent_cpu for the current
thread. If we are on an exact multiple of a second after boot, then we update
the load average and the recent_cpu for every thread. Every 4th tick we
recalculate thread priority in the advanced scheduler.

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

The amount of code in the interrupt handler is very small, especially for the
normal scheduler. In the check_thread function, we take advantage of the short-
circuited "&&" operation to save on valuable computation time.

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

Interrupts are disabled around the call to thread_block (which has to be done
before this function is called), which completely removes any potential
synchronisation issues and thus avoids the possibility of race conditions.

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

Interrupts are disabled during the call to thread_block in timer_sleep(). Since
the timer interrupt is not a non-maskable external interrupt, it can be
postponed by disabling interrupts, and we can avoid the possibility of race
conditions in this case.

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

We considered maintaining a list of blocked threads, sorted in order of
time_to_sleep. Then the front of this list could be peeked at to see if it
needed to be unblocked. However, this would require quite a lot of list
manipulation within the timer interrupt, and needs more space. It's possible
that this method could also cause issues if more than one thread was put to
sleep at almost exactly the same time: if you only check the front of the list
then you could end up un-sleeping a thread too late. To get around this you
might have to loop through the list at every timer tick, which becomes even
more complicated and wasteful.

The method we chose is easy to reason about was very simple to implement. We
didn't need to create any new data structures, which means that space
complexity is kept to a minimum. We didn't need to write many new methods, as
our method just utilised the thread_block and thread_unblock methods.

             PRIORITY SCHEDULING
             ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

struct thread
  {
    :
    :
    snip
    :
    :

    /* Priority donation */
    int base_priority;                  /* Pri. thread was initialised with */
    struct list locks_held;             /* Locks this thread holds */
    struct thread *donee;               /* Thread this thread is currently
                                            donating to */
    :
    :
    snip
    :
    :
  };

The base_priority member keeps track of a thread's base priority, since the
priority member is now increased whenever a thread receives a priority donation. 

locks_held is a list of all locks currently held by a thread. This is used to
recalculate a thread's priority after a lock is released, or its base priority
isupdated.

The donee member is a pointer to the thread (if any) that a thread is currently
donating its priority to.


static struct lock set_pri_lock;  /* Ensures only one thread setting priority
                                     at any given time. */


The static variable set_pri_lock is used to ensure that only one call to
thread_set_priority can take place at any given time. This is explained in
answer B6 below.


>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

As explained above, the donee member of a thread is a pointer to the thread (if
any) that a thread is currently donating to. This works, as a thread can only
donate to at most one other thread.

The below diagram shows a nested donation, where pri (h) > pri (m) > pri (l),
and h's priority has been donated to l. This is modelled on the priority-donate-
nest test.

 +---------+ donee +---------+ donee +---------+ donee
 |    h    |------>|    m    |------>|    l    |------> NULL
 +---------+       +---------+       +---------+


---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

When a semaphore is 'upped', the thread with the maximum priority is chosen to
be woken up by using the list_max function with the thread_sort_func in
thread.c. This means even if threads have been donated to since being put in the
list, sema_up will still wake the highest priority one. We considered using a
sorted list and popping threads off the front, but this would not have worked
as the list would become incorrectly ordered when a thread receives a donation.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

When a lock_acquire() call causes a priority donation, the thread's donee member
is updated to reflect the donation and its priority is updated. A while loop is
used to handle nested donation, traversing the chain of donations as illustrated
above in B2, updating a thread's priority only when it would lead to an increase
in its value.

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

              ADVANCED SCHEDULER
              ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

struct thread
  {
    :
    :
    snip
    :
    :

    /* Used by advanced scheduler */
    int niceness;                       /* The thread's niceness value */
    fixed_point_t recent_cpu;           /* Estimate of recent cpu time */
  };

The niceness member keeps track of the thread's niceness value, as detailed in
appendix B1 of the specification.

The recent_cpu member holds the value of the thread's recent CPU usage, which
is initialised to 0 when the thread is created. It is stored as a fixed point
representation of a real number.


typedef int32_t fixed_point_t;

This is used by recent_cpu and load_avg. Although this is just an
integer, using this typedef makes the intent of functions and variables much
clearer.


static fixed_point_t load_avg;

This is the system-wide load_avg value, used by all threads to calculate their
recent_cpu and priorities.


---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0      0   0   0  63  61  59   A
 4      4   0   0  62  61  59   A
 8      8   0   0  61  61  59   B
12      8   4   0  61  60  59   A
16     12   4   0  60  60  59   B
20     12   8   0  60  59  59   A
24     16   8   0  59  59  59   C
28     16   8   4  59  59  58   B
32     16  12   4  59  58  58   A
36     20  12   4  58  58  58   C



>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behaviour of your scheduler?

Some of the equations given in the fixed point mathematics section could be
considered ambiguous, depending on whether you read them left-to-right or not.
For example, the equations to multiply and divide two fixed point numbers could
be read in two different ways due to lack of bracketing.

In our fixed point methods we left the equations exactly as they were in the
specification, with no extra bracketing.

NB: For filling in the values in C2, we have assumed that a second does not
    tick over at any point during the 36 ticks (they are all contained within a
    second), so recent_cpu is not recalculated for all threads and the value
    of load_avg is therefore not important.



>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

The majority of calculation for thread priorities is done in the timer
interrupt, because the values of recent_cpu, load average and thread priority
have to be calculated at a certain tick. This is likely to have some impact on
performance, but the calculations that need to be performed in the interrupt are
relatively simple. We avoid doing any CPU yielding - a resource heavy task -
during the timer interrupt by using the intr_yeild_on_return function whenever
possible. The mlfqs-load-avg test passes with hardly any discrepancy between the
expected and actual output, so the amount of computation performed in the
interrupt handler is clearly suitable.



---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the task, how might you choose to
>> refine or improve your design?

The design is fairly solid on the whole. The methods that deal with all of the
calculations for statistics such as load average and recent_cpu are split up
into smaller steps, as opposed to having one big line of code that computes the
entire result. Doing this makes the formulae a lot easier to understand.

The method names for the fixed point mathematical operations have very clear
meaning, which makes understanding what each method and each formula does even
easier.

Where possible, #define is used to remove any magic numbers from the code and
make it as easy to read as possible.

We decided that having a queue for each priority was unnecessary, and kept a
single queue as before. The behaviour of the list_insert_ordered function
means that the multi-level queue system can be implemented in a single queue
very easily.



>> C6: The assignment explains arithmetic for fixed-point mathematics in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point mathematics, that is, an abstract
>> data type and/or a set of functions or macros to manipulate
>> fixed-point numbers, why did you do so?  If not, why not?

The fixed-point mathematics is implemented in a separate file, arithmetic.c. The
thread.c file then contains an include for the header file arithmetic.h, which
contains the function prototypes. Abstracting the functions in this way makes
the code in thread.c a lot simpler and more readable. Having a set of functions
reduces code duplication, as functions can be re-used in multiple places. Thanks
to the typedef fixed_point_t, it is very clear which functions are supposed to
convert from integers to fixed point representations and vice-versa. It is also
very clear if a variable should be a fixed point representation or and integer,
which helped a lot when debugging errors in the formula.



               SURVEY QUESTIONS
               ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining tasks?

Most lab helpers need to do some reading/become acquainted with the project
before trying to help in labs.

>> Any other comments?
